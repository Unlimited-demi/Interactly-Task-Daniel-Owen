{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a65a2ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data upload complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Initialize Elasticsearch with the Cloud ID and API key\n",
    "client = Elasticsearch(\n",
    "    \"https://a219db0c9a52430d82ebb7ad71ed5b02.us-central1.gcp.cloud.es.io:443\",\n",
    "    api_key=\"X1o2eThwQUJyZHhtemJ2SS1RTVM6NGo1c0NCMTJRZUNzQlh4QUlyZVJrZw==\"\n",
    ")\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = '../data/candidate_data.csv'  # Update with your actual CSV file path\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Define the index name\n",
    "index_name = 'candidates'\n",
    "\n",
    "# Function to upload a document to Elasticsearch\n",
    "def upload_document(row):\n",
    "    document = row.to_dict()\n",
    "    response = client.index(index=index_name, document=document)\n",
    "    return response\n",
    "\n",
    "# Iterate over DataFrame rows and upload each document to Elasticsearch\n",
    "for index, row in df.iterrows():\n",
    "    upload_document(row)\n",
    "\n",
    "print(\"Data upload complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb2e1d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'instance-0000000000', 'cluster_name': 'a219db0c9a52430d82ebb7ad71ed5b02', 'cluster_uuid': 'fapDlR6GRsWfdsQfXYaudw', 'version': {'number': '8.14.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'd55f984299e0e88dee72ebd8255f7ff130859ad0', 'build_date': '2024-07-07T22:04:49.882652950Z', 'build_snapshot': False, 'lucene_version': '9.10.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc12983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Initialize MongoDB with the provided URI\n",
    "uri = \"mongodb+srv://unlimiteddemi:tBLzzgx35XlDQmKr@cluster0.ddje26o.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "mongo_client = MongoClient(uri)\n",
    "db = mongo_client['candidate_db']\n",
    "profiles_collection = db['profiles']\n",
    "\n",
    "# Initialize Elasticsearch\n",
    "client = Elasticsearch(\n",
    "    \"https://a219db0c9a52430d82ebb7ad71ed5b02.us-central1.gcp.cloud.es.io:443\",\n",
    "    api_key=\"9Z7KxWAnTrmZhfcxFrxsVw\"\n",
    ")\n",
    "\n",
    "\n",
    "# Load the fine-tuned GPT-2 model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('../models/fine_tuned_gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('../models/fine_tuned_gpt2')\n",
    "\n",
    "def retrieve_profiles_from_mongo(job_description):\n",
    "    matching_profiles = profiles_collection.find({\"Job Skills\": {\"$regex\": job_description, \"$options\": \"i\"}})\n",
    "    return list(matching_profiles)\n",
    "\n",
    "def retrieve_profiles_from_es(job_description):\n",
    "    response = client.search(\n",
    "        index='candidates',\n",
    "        body={\n",
    "            'query': {\n",
    "                'match': {\n",
    "                    'Job Skills': job_description\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return [hit['_source'] for hit in response['hits']['hits']]\n",
    "\n",
    "def generate_profiles(retrieved_profiles):\n",
    "    input_text = \"Matching profiles:\\n\" + \"\\n\".join([str(profile) for profile in retrieved_profiles])\n",
    "    inputs = tokenizer(input_text, return_tensors='pt')\n",
    "    outputs = model.generate(inputs['input_ids'], max_length=512)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def interactive_cli():\n",
    "    print(\"Welcome to the Interactive Profile Matcher!\")\n",
    "    print(\"Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        query = input(\"Enter job description: \")\n",
    "        if query.lower() == 'exit':\n",
    "            break\n",
    "\n",
    "        source = input(\"Enter data source (mongo/es): \").lower()\n",
    "        if source not in ['mongo', 'es']:\n",
    "            print(\"Invalid source. Please enter 'mongo' or 'es'.\")\n",
    "            continue\n",
    "\n",
    "        if source == 'mongo':\n",
    "            profiles = retrieve_profiles_from_mongo(query)\n",
    "        else:\n",
    "            profiles = retrieve_profiles_from_es(query)\n",
    "\n",
    "        if not profiles:\n",
    "            print(\"No matching profiles found.\")\n",
    "        else:\n",
    "            summary = generate_profiles(profiles)\n",
    "            print(\"\\nResults:\\n\")\n",
    "            print(summary)\n",
    "            print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_cli()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
